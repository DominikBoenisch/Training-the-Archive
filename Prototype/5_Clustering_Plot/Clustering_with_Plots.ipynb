{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAMfWshUCye9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.offsetbox import OffsetImage,AnnotationBbox\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1kQHjSJHAcC"
   },
   "source": [
    "### Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're working with Colab mount your drive or skip this step\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRsHllJPC2lH"
   },
   "outputs": [],
   "source": [
    "scraped_images_folder = '/set/the/path/to/your/scraped/images/'\n",
    "                 \n",
    "feature_files = [('/path/to/file/BiT-m-r152x4_feature.npz', 0.9),\n",
    "                 ('/path/to/another/feature_file.npz', None),\n",
    "                 ('/path/to/another/feature_file.npz', 10)\n",
    "                 ]\n",
    "\n",
    "# Here you must now specify a list of tuples with the form (feature_file, components).\n",
    "# Components is the parameter for the PCA or is set to None.\n",
    "# You can stack different feature-files and combine them.\n",
    "# PCA: Reduce the number of dimensions to n_components  \n",
    "# If n_components is between 0-1 it controlls the fraction of explained variance\n",
    "# If it is integer, it controlls the number of components directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9OCqNOusTy_"
   },
   "outputs": [],
   "source": [
    "# fix feature files if necessary\n",
    "for feature_file,_ in feature_files:\n",
    "    feature_dict = np.load(feature_file)\n",
    "    keys = list(feature_dict.keys())\n",
    "    if \"'\" in keys[0]:\n",
    "        print('fixing '+feature_file)\n",
    "        new_dict = {}\n",
    "        for k in keys:\n",
    "            new_dict[k.replace(\"'\",'')] = feature_dict[k]\n",
    "        np.savez(feature_file, **new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qK5M2zDnHH6h"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "MbhuyrdrRNJw",
    "outputId": "02285d68-9e44-4eb1-c2c8-fb260599a584",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collect all the feature files\n",
    "feature_dicts = []\n",
    "image_name_lists = []\n",
    "for feature_file,components in feature_files:\n",
    "    feature_dict = dict(np.load(feature_file))\n",
    "    # do local pca on features\n",
    "    pca = PCA(n_components = components,whiten = True)\n",
    "    image_names = np.array(list(feature_dict.keys()))\n",
    "    features = np.array(list(feature_dict.values()))\n",
    "    features = pca.fit_transform(features)\n",
    "    feature_dict = dict(zip(image_names,features))\n",
    "    feature_dicts.append(feature_dict) \n",
    "    keys =feature_dict.keys()\n",
    "    image_name_lists.append(keys)\n",
    "    print(f'using {features.shape[1]} features from {feature_file}')\n",
    "\n",
    "# make sure we use only image names occuring in all files\n",
    "image_names  = set(image_name_lists[0])\n",
    "for image_name_list in image_name_lists[1:]:\n",
    "    image_names = image_names.intersection(set(image_name_list))\n",
    "image_names = list(image_names)\n",
    "\n",
    "features = []\n",
    "for image_name in image_names:\n",
    "    feature = []\n",
    "    for feature_dict in feature_dicts:\n",
    "        feature.append(feature_dict[image_name])\n",
    "    features.append(np.concatenate(feature))\n",
    "\n",
    "image_names = np.array(image_names)\n",
    "all_features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_ha8wJL2ZuUq",
    "outputId": "be33fa01-69c1-4946-977c-def43f0654d2"
   },
   "outputs": [],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bDiaFgm5Uixn",
    "outputId": "c968f919-2a20-48e1-b004-75a4d232dde6"
   },
   "outputs": [],
   "source": [
    "# reduce the number of dimensions to n_components  \n",
    "# if n_components is between 0-1 it controlls the fraction of explained variance\n",
    "# if it is integer, it controlls the number of components directly\n",
    "pca = PCA(n_components = 0.9, whiten = True)\n",
    "features = pca.fit_transform(all_features)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = all_features # if you are not running a second PCA\n",
    "#features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQCL1oqSDedg"
   },
   "outputs": [],
   "source": [
    "# for plotting only\n",
    "pca2d = PCA(n_components = 2,whiten = True)\n",
    "features_pca2d = pca2d.fit_transform(features)\n",
    "tsne2d = TSNE(n_components =2 )\n",
    "features_tsne2d = tsne2d.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pca2d.shape # checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tsne2d.shape # checksum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5yE23RlHLPs"
   },
   "source": [
    "### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIsQJJvEC2sO"
   },
   "outputs": [],
   "source": [
    "max_samples = -1 # set to a part of the data f.e. 20000 or to -1 if all samples should be considered\n",
    "\n",
    "l = linkage(features[:max_samples], 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Sv44VVY5C8k3",
    "outputId": "f3e77dcf-4676-470b-8210-d7e071e4ada9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 236\n",
    "\n",
    "main_clusters_tmp = fcluster(l, criterion='distance', t=threshold)\n",
    "print(f'{np.max(main_clusters_tmp)} cluster created')\n",
    "\n",
    "main_clusters = {}\n",
    "for cluster_number in range(1, main_clusters_tmp.max()):\n",
    "    main_clusters[cluster_number] = np.where(main_clusters_tmp == cluster_number)[0]\n",
    "    print(f'cluster {cluster_number} has {len(main_clusters[cluster_number])} member')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMH-51Vpc1uG"
   },
   "source": [
    "### Filter Copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dM63_YJGbV32"
   },
   "outputs": [],
   "source": [
    "legalize = True # the filter is switched on (True) or off (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auaY0aFNYwTW"
   },
   "outputs": [],
   "source": [
    "def clean_images(members,image_names):\n",
    "    copyright_file = '/set/the/path/to/the/file/is_public.json'\n",
    "    with open(copyright_file) as json_file:\n",
    "        is_public = json.load(json_file)\n",
    "    new_members = []\n",
    "    for member in members:\n",
    "        if is_public[image_names[member]]:\n",
    "            new_members.append(member)\n",
    "    return np.array(new_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcGwORlqHPZN"
   },
   "source": [
    "### Visualize cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HeWWLYtnEII"
   },
   "outputs": [],
   "source": [
    "def vis_cluster(cluster_number, clustering, img_per_row,mode = 'tsne_scatter',zoom=0.4,local_reduction = True):\n",
    "    \"\"\" modes: grid         - arrangement in a grid\n",
    "               pca_grid     - grid influenced by the PCA\n",
    "               pca_scatter  - scatterplot influenced by the PCA\n",
    "               tsne_grid    - grid influenced by the TSNE\n",
    "               tsne_scatter - scatterplot influenced by the TSNE\n",
    "        local_reduction: True   - PCA or TSNE is only calculated on the visualized cluster\n",
    "                         False  - PCA or TSNE is calculated on all data\n",
    "        zoom: size of the images in the scatterplot\n",
    "    \"\"\"\n",
    "    members = clustering[cluster_number]\n",
    "    if legalize:\n",
    "        members = clean_images(members,image_names)\n",
    "    member_images = [os.path.join(scraped_images_folder, image_names[m].strip(\"'\")) for m in members]\n",
    "    if mode == 'grid':\n",
    "        plt.figure(figsize=(30, math.ceil(len(members)/img_per_row)*(25/img_per_row)))\n",
    "        for i, member in enumerate(members):\n",
    "            plt.subplot(math.ceil(len(members)/img_per_row), img_per_row, i+1) \n",
    "            im_name = member_images[i]\n",
    "            im = image.load_img(im_name, target_size=(224,224))\n",
    "            plt.imshow(im)\n",
    "            plt.axis(False)\n",
    "    else:\n",
    "        member_features =  features[members]\n",
    "        if 'pca' in mode:\n",
    "            if local_reduction:\n",
    "                member_pca = PCA(n_components=2,whiten  =True)\n",
    "                member_positions = member_pca.fit_transform(member_features)\n",
    "            else:\n",
    "                member_positions = features_pca2d[members]\n",
    "        elif 'tsne' in mode:\n",
    "            if local_reduction:\n",
    "                member_tsne = TSNE(n_components=2)\n",
    "                member_positions = member_tsne.fit_transform(member_features)\n",
    "            else:\n",
    "                member_positions = features_tsne2d[members]\n",
    "\n",
    "        if 'scatter' in mode:\n",
    "            plt.figure(figsize = (30,30))\n",
    "            ax = plt.subplot(111)\n",
    "            for pos,im_name in zip(member_positions,member_images):\n",
    "                img = image.load_img(im_name, target_size=(224,224))\n",
    "                im = OffsetImage(img, zoom=zoom)\n",
    "                ab = AnnotationBbox(im, pos, xycoords='data', frameon=False)\n",
    "                ax.add_artist(ab)\n",
    "                ax.update_datalim(np.column_stack(pos))\n",
    "                ax.autoscale()\n",
    "            plt.axis(False)\n",
    "\n",
    "        \n",
    "        elif 'grid' in mode:\n",
    "            n_rows = math.ceil(len(members)/img_per_row)\n",
    "            plt.figure(figsize=(30, n_rows*(25/img_per_row)))\n",
    "            subplot_ind = 1\n",
    "            remaining_members = range(len(members))\n",
    "\n",
    "            while len(remaining_members)>0:\n",
    "                # find the highest img_per_row members\n",
    "                order = np.argsort(member_positions[remaining_members,1])\n",
    "                top_members = [remaining_members[m] for m in order[-img_per_row:]]\n",
    "                remaining_members =  [m for m in remaining_members if m not in top_members]\n",
    "                # sort from left to right\n",
    "                order = np.argsort(member_positions[top_members,0])\n",
    "                for o in order:\n",
    "                    plt.subplot(math.ceil(len(members)/img_per_row), img_per_row, subplot_ind) \n",
    "                    im_name = member_images[top_members[o]]\n",
    "                    im = image.load_img(im_name, target_size=(224,224))\n",
    "                    plt.imshow(im)\n",
    "                    plt.axis(False)\n",
    "                    subplot_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uK8Dvf6N2j9H"
   },
   "outputs": [],
   "source": [
    "vis_cluster(\n",
    "    cluster_number = 34, # set the cluster you want to visualize\n",
    "    clustering = main_clusters,\n",
    "    img_per_row = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkP7MOso_mA0"
   },
   "source": [
    "#### Visualization: Cluster with \"Hierarchical Family Tree (Maincluster)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kG-0lcVpLAA"
   },
   "outputs": [],
   "source": [
    "def do_visual_clustering(clusters, cluster2subcluster, threshold, image_size):\n",
    "    members = clusters[cluster2subcluster]\n",
    "    if legalize:\n",
    "        members = clean_images(members,image_names)\n",
    "    l2 = linkage(features[members], 'ward')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, len(members)*image_size))\n",
    "    plt.subplot(ax1)\n",
    "    d = dendrogram(l2, orientation='left', color_threshold=threshold)\n",
    "    ax1.set_yticklabels([])\n",
    "    gs = matplotlib.gridspec.GridSpecFromSubplotSpec(subplot_spec=ax2, ncols = 1, nrows=len(members))\n",
    "    for ix, img_nr in enumerate(d['leaves']):\n",
    "        plt.subplot(gs[ix])\n",
    "        im_name = os.path.join(scraped_images_folder, image_names[members[img_nr]].strip(\"'\"))\n",
    "        im = image.load_img(im_name, target_size=(224,224))\n",
    "        plt.imshow(im)\n",
    "        plt.axis(False)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gpryVz-z1gTX",
    "outputId": "59a4b726-d15e-49ea-cb9e-2644dc9d6842"
   },
   "outputs": [],
   "source": [
    "d = do_visual_clustering(\n",
    "    clusters = main_clusters,\n",
    "    cluster2subcluster = 8, # set the cluster you want to visualize\n",
    "    threshold = 20, # only visual cluster cut\n",
    "    image_size = 1.5 # determines how large images are printed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecn2pQBp_7GY"
   },
   "source": [
    "### Subclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW8kpuwglpy9"
   },
   "outputs": [],
   "source": [
    "def do_subclustering(clusters, cluster2subcluster, threshold):\n",
    "    \n",
    "    main_cluster_members = clusters[cluster2subcluster]\n",
    "    l2 = linkage(features[main_cluster_members], 'ward')\n",
    "    sub_clusters_tmp = fcluster(l2, criterion='distance', t=threshold)\n",
    "    print(f'{np.max(sub_clusters_tmp)} cluster created')\n",
    "\n",
    "    sub_clusters = {}\n",
    "    for cluster_number in range(1, sub_clusters_tmp.max()):\n",
    "        sub_clusters[cluster_number] = [main_cluster_members[i] for i in np.where(sub_clusters_tmp == cluster_number)[0]]\n",
    "        print(f'cluster {cluster_number} has {len(sub_clusters[cluster_number])} member')\n",
    "\n",
    "    return sub_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "gDfYBzhSUXPM",
    "outputId": "c93a0bc3-04fc-4b99-e7c3-f64252a442e1"
   },
   "outputs": [],
   "source": [
    "sub_cluster = do_subclustering(\n",
    "    clusters = main_clusters,\n",
    "    cluster2subcluster = 6, # set a large cluster to divide it in subcluster\n",
    "    threshold = 2\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Dvl46F8RTZme",
    "outputId": "6b4ebed6-53e9-4e81-82c5-649c053e42f8"
   },
   "outputs": [],
   "source": [
    "vis_cluster(\n",
    "    cluster_number = 2, # set the subcluster you want to visualize\n",
    "    clustering = sub_cluster,\n",
    "    img_per_row = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VHgjmwvAHdS"
   },
   "source": [
    "#### Visualization: Cluster with \"Hierarchical Family Tree (Subcluster)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nwlTtdgJrrSc",
    "outputId": "2e70d235-3c58-4f66-8470-42d37b82da79"
   },
   "outputs": [],
   "source": [
    "d = do_visual_clustering(\n",
    "    clusters = sub_cluster,\n",
    "    cluster2subcluster = 2, # set the subcluster you want to visualize\n",
    "    threshold = 5, # only visual cluster cut\n",
    "    image_size = 3 # determines how large images are printed\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Projekt4.3 - Clustering (Feature-Addition_mit Style-Layer)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
